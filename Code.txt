from google.colab import drive
drive.mount('/content/drive')

%matplotlib inline
from IPython import display
import os
import math
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn.metrics import *
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from keras.applications.vgg19 import VGG19, preprocess_input
import shutil
import plotly.graph_objs as go
from plotly.offline import init_notebook_mode, iplot
from plotly import tools
import imutils

np.random.seed(42)
tf.random.set_seed(42)

#Setting some inital parameters
height, width = 224, 224
IMG_SIZE = (224,224)
batch_size=64
DIR='/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/'
!apt-get install tree
#clear_output()
# create new folders
!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO
!tree -d

def load_data(dir_path, img_size=(224,224)):
    """
    Load resized images as np.arrays to workspace
    """
    X = []
    y = []
    i = 0
    labels = dict()
    for path in tqdm(sorted(os.listdir(dir_path))):
        if not path.startswith('.'):
            labels[i] = path
            for file in os.listdir(dir_path + path):
                if not file.startswith('.'):
                    img = cv2.imread(dir_path + path + '/' + file)
                    X.append(img)
                    y.append(i)
            i += 1
    X = np.array(X)
    y = np.array(y)
    print(f'{len(X)} images loaded from {dir_path} directory.')
    return X, y, labels
!mkdir  augmented-images augmented-images/yes augmented-images/no
import os
from os import listdir
def augment_data(file_dir, n_generated_samples, save_to_dir):
    data_gen = ImageDataGenerator(rotation_range=10, 
                                  width_shift_range=0.1, 
                                  height_shift_range=0.1, 
                                  shear_range=0.1, 
                                  brightness_range=(0.3, 1.0),
                                  horizontal_flip=True, 
                                  vertical_flip=True, 
                                  fill_mode='nearest'
                                 )

    for filename in listdir(file_dir):
        image = cv2.imread(file_dir + '/' + filename)
        # reshape the image
        image = image.reshape((1,)+image.shape)
        save_prefix = 'aug_' + filename[:-4]
        i=0
        
#         if (filename=='N1' or filename=='N11' or filename=='N15' or filename=='N16' or filename=='N17' or filename=='N19' or filename=='N22'): 
#             for batch in data_gen.flow(x=image, batch_size=1, save_to_dir='yes',save_prefix=save_prefix, save_format='jpg'):
#                 i += 1
#                 if i > n_generated_samples:
#                     break
#         elif (filename=='Y185' or filename=='Y187'):
#             for batch in data_gen.flow(x=image, batch_size=1, save_to_dir='no',save_prefix=save_prefix, save_format='jpg'):
#                 i += 1
#                 if i > n_generated_samples:
#                     break
#         else:
        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,save_prefix=save_prefix, save_format='jpg'):
                i += 1
                if i > n_generated_samples:
                    break
                    
                    
augmented_data_path ='/content/augmented-images/'
# augment data for the examples with label equal to 'yes' representing tumurous examples
augment_data(file_dir=DIR+'yes',n_generated_samples=7, save_to_dir=augmented_data_path+'yes')
# augment data for the examples with label equal to 'no' representing non-tumurous examples
augment_data(file_dir=DIR+'no', n_generated_samples=10, save_to_dir=augmented_data_path+'no')
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator

def augment_and_display(file_path, n_generated_samples):
    data_gen = ImageDataGenerator(rotation_range=10, 
                                  width_shift_range=0.1, 
                                  height_shift_range=0.1, 
                                  shear_range=0.1, 
                                  brightness_range=(0.3, 1.0),
                                  horizontal_flip=True, 
                                  vertical_flip=True, 
                                  fill_mode='nearest'
                                 )

    image = cv2.imread(file_path)
    # reshape the image
    image = image.reshape((1,)+image.shape)
    save_prefix = 'aug_' + os.path.basename(file_path)[:-4]
    i=0
    
    for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=None):
        augmented_image = batch[0].astype(np.uint8)
        plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))
        plt.show()
        i += 1
        if i > n_generated_samples:
            break

# Example usage
image_path = '/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/yes/Y102.jpg'
# Generate augmented images for the single image and display them
augment_and_display(file_path=image_path, n_generated_samples=9)
X, y, labels = load_data(DIR, IMG_SIZE)
DIR1='/content/augmented-images/'
X1, y1, labels1 = load_data(DIR1, IMG_SIZE)
import numpy as np
import random

class KMeansDPSO:
    
    def __init__(self, k, num_particles, num_iterations):
        self.k = k
        self.num_particles = num_particles
        self.num_iterations = num_iterations
        
    def fit(self, X):
        self.X = X
        self.num_samples = X.shape[0]
        self.num_features = X.shape[1]
        
        # Initialize particles
        self.particles = np.zeros((self.num_particles, self.k, self.num_features))
        for i in range(self.num_particles):
            self.particles[i] = self._initialize_centers()
            
        # Initialize global best particle
        self.global_best_particle = self.particles[0]
        self.global_best_cost = float('inf')
        
        # Initialize velocity and personal best for each particle
        self.velocity = np.zeros((self.num_particles, self.k, self.num_features))
        self.personal_best_particle = np.zeros((self.num_particles, self.k, self.num_features))
        self.personal_best_cost = np.zeros(self.num_particles)
        for i in range(self.num_particles):
            self.personal_best_particle[i] = self.particles[i]
            cost = self._get_cost(self.particles[i])
            self.personal_best_cost[i] = cost
            if cost < self.global_best_cost:
                self.global_best_particle = self.particles[i]
                self.global_best_cost = cost
        
        # Update particles
        for iteration in range(self.num_iterations):
            for i in range(self.num_particles):
                # Update velocity
                r1 = random.uniform(0, 1)
                r2 = random.uniform(0, 1)
                self.velocity[i] = r1 * self.velocity[i] + r2 * (self.personal_best_particle[i] - self.particles[i])
                
                # Update particle
                self.particles[i] += self.velocity[i]
                
                # Apply MR operation
                self.particles[i] = self._mr_operation(self.particles[i])
                
                # Update personal best
                cost = self._get_cost(self.particles[i])
                if cost < self.personal_best_cost[i]:
                    self.personal_best_particle[i] = self.particles[i]
                    self.personal_best_cost[i] = cost
                    
                    # Update global best
                    if cost < self.global_best_cost:
                        self.global_best_particle = self.particles[i]
                        self.global_best_cost = cost
                        
        # Assign labels to data points based on the final particle
        self.labels = np.zeros(self.num_samples)
        for i in range(self.num_samples):
            distances = np.linalg.norm(self.global_best_particle - self.X[i], axis=1)
            self.labels[i] = np.argmin(distances)
            
    def _initialize_centers(self):
      centers = np.zeros((self.k, self.num_features))
      for i in range(self.k):
        idx = random.randint(0, self.num_samples-1)
        centers[i] = np.ravel(self.X[idx])[0]
      return centers

    
    def _get_cost(self, centers):
        distances = np.linalg.norm(centers - self.X[:, np.newaxis], axis=2)
        return np.sum(np.min(distances, axis=1))
    
    def _mr_operation(self, centers):
      # Mutation
      r = random.uniform(0, 1)
      if r < 0.1:
        i = random.randint(0, self.k-1)
        j = random.randint(0, self.num_features-1)
        centers[i, j] = random.uniform(np.min(self.X[:,j]), np.max(self.X[:,j]))
      # Reflection
      for i in range(self.k):
        for j in range(self.num_features):
            if centers[i, j] < np.min(self.X[:,j]):
                centers[i, j] = np.min(self.X[:,j]) + random.uniform(0, 1) * (centers[i, j] - np.min(self.X[:,j]))
            elif centers[i, j] > np.max(self.X[:,j]):
                centers[i, j] = np.max(self.X[:,j]) - random.uniform(0, 1) * (np.max(self.X[:,j]) - centers[i, j])
      return centers

def improved_kmeans_segment1(set_name, img_size):
    set_new = []
    for i, img in enumerate(set_name):
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # reshape the image to a 2D array of pixels and 3 color values (RGB)
        pixel_values = img.reshape((-1, 3))
        # convert to float
        pixel_values = np.float32(pixel_values)
        # define stopping criteria
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
        # number of clusters (K)
        k = 3
        _, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_PP_CENTERS)
        # convert back to 8 bit values
        centers = np.uint8(centers)
        # flatten the labels array
        labels = labels.flatten()
        # convert all pixels to the color of the centroids
        segmented_image = centers[labels.flatten()]
        # reshape back to the original image dimension
        segmented_image = segmented_image.reshape(img.shape)
        set_new.append(preprocess_input(segmented_image))
        if i >= 5 and i <= 7:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
            ax1.imshow(img)
            ax1.set_title('Original Image')
            ax1.axis('off')
            ax2.imshow(segmented_image)
            ax2.set_title('Segmented Image')
            ax2.axis('off')
            plt.show()
    return np.array(set_new)
def improved_kmeans_segment(set_name, img_size):
    set_new = []
    for img in set_name:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # reshape the image to a 2D array of pixels and 3 color values (RGB)
        pixel_values = img.reshape((-1, 3))
        # convert to float
        pixel_values = np.float32(pixel_values)
        # define stopping criteria
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
        # number of clusters (K)
        k = 5
        _, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        # convert back to 8 bit values
        centers = np.uint8(centers)
        # flatten the labels array
        labels = labels.flatten()
        # convert all pixels to the color of the centroids
        segmented_image = centers[labels.flatten()]
        # reshape back to the original image dimension
        segmented_image = segmented_image.reshape(img.shape)
        set_new.append(preprocess_input(segmented_image))
    return np.array(set_new)
def crop_imgs(set_name, add_pixels_value=0):
    """
    Finds the extreme points on the image and crops the rectangular out of them
    """
    set_new = []
    for img in set_name:
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 0)

        # threshold the image, then perform a series of erosions +
        # dilations to remove any small regions of noise
        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
        thresh = cv2.erode(thresh, None, iterations=2)
        thresh = cv2.dilate(thresh, None, iterations=2)

        # find contours in thresholded image, then grab the largest one
        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = imutils.grab_contours(cnts)
        c = max(cnts, key=cv2.contourArea)

        # find the extreme points
        extLeft = tuple(c[c[:, :, 0].argmin()][0])
        extRight = tuple(c[c[:, :, 0].argmax()][0])
        extTop = tuple(c[c[:, :, 1].argmin()][0])
        extBot = tuple(c[c[:, :, 1].argmax()][0])

        ADD_PIXELS = add_pixels_value
        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()
        set_new.append(new_img)

    return np.array(set_new)
#apply this for the set
X_crop = crop_imgs(set_name=X)
def save_new_images(x_set, y_set, folder_name):
    i = 0
    for (img, imclass) in zip(x_set, y_set):
        if imclass == 0:
            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)
        else:
            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)
        i += 1
# saving new images to the folder
!mkdir CROPPED_DATA CROPPED_DATA/YES CROPPED_DATA/NO 
save_new_images(X_crop, y, folder_name='CROPPED_DATA/')
#apply this for each set
X_segm =improved_kmeans_segment1(set_name=X_crop, img_size=IMG_SIZE)
# saving new images to the folder
!mkdir DATA_SEGMENT DATA_SEGMENT/YES DATA_SEGMENT/NO 

save_new_images(X_segm, y1, folder_name='DATA_SEGMENT/')
DIR='/content/DATA_SEGMENT'

def image_generator(height,width):
    datagen = ImageDataGenerator(
            rescale=1./255.,
            validation_split=0.3
            
            )
    train1_ds = datagen.flow_from_directory(
            DIR,
            batch_size=batch_size,
            subset="training",
            #color_mode = 'grayscale',
            shuffle=True,
            class_mode='binary',
            target_size=(height, width),
            classes={'NO': 0., 'YES': 1.}
            )
    val1_ds = datagen.flow_from_directory(
              DIR,
              subset="validation",
              #seed=123,
              #color_mode = 'grayscale',
              class_mode='binary',
              target_size=(height, width),
              batch_size=batch_size,
              classes={'NO': 0., 'YES': 1.}
            )
    return train1_ds, val1_ds

train1_ds, val1_ds = image_generator(height,width)

total_image = np.concatenate([train1_ds.labels,val1_ds.labels])
print('\n\n',{'No_brain_tumor_cases':len(np.where(total_image==0)[0]),
      'brain_tumor_cases':len(np.where(total_image==1)[0])})
def augmentataion_generator(height,width):
    datagen = ImageDataGenerator(
            rescale=1./255.,
            width_shift_range=0.1,
            height_shift_range=0.1,
            shear_range=0.1,
            zoom_range=0.1,
            rotation_range=30,
            horizontal_flip=True,
            brightness_range=(0.5, 1.0)
            )
    aug_train_ds = datagen.flow_from_directory(
              DIR,
            batch_size=64,
            shuffle=True,
            class_mode='binary',
            target_size=(height, width),
            classes={'NO': 0., 'YES': 1.}
            )
    return aug_train_ds
aug_train_ds = augmentataion_generator(height,width)
from tensorflow.keras.layers.experimental import preprocessing
tf.keras.backend.clear_session()
input_shape = (height, width, 3)
base_model = tf.keras.applications.vgg19.VGG19(
    weights='imagenet', 
    include_top=False,
    input_shape=input_shape
)
base_model.trainable = False
model_vgg19 = tf.keras.Sequential()
model_vgg19.add(base_model)
model_vgg19.add(tf.keras.layers.Flatten())
model_vgg19.add(tf.keras.layers.Dense(1, activation='sigmoid'))
model_vgg19.compile(loss='binary_crossentropy', 
              optimizer=tf.keras.optimizers.Adam(0.01),
              metrics=['acc'])
model_vgg19.summary()
from keras import models, layers, optimizers

# Create the base model
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Add a new dense layer with sigmoid activation function
x = base_model.output
x = layers.Flatten()(x)
x = layers.Dense(256, activation='relu')(x)
predictions = layers.Dense(1, activation='sigmoid')(x)

# Create a new model with the base model and new dense layer
model_vgg19_svm = models.Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model_vgg19_svm.compile(optimizer=optimizers.RMSprop(lr=2e-5),
                         loss='binary_crossentropy',
                         metrics=['acc'])

model_vgg19_svm.summary()
checkpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg19_best.h5', monitor='acc', verbose=1, mode='max',save_best_only=True)
early = tf.keras.callbacks.EarlyStopping(monitor="acc", mode="max",restore_best_weights=True, patience=5)
callbacks_list = [checkpoint,early]

history = model_vgg19_svm.fit(
        train1_ds,
        validation_data=val1_ds,
        epochs=25, 
        shuffle=True, 
        verbose=True,
        callbacks=callbacks_list)
train_result = model_vgg19.evaluate(train1_ds)
val_result = model_vgg19.evaluate(val1_ds)

augmented_df = pd.DataFrame(zip(train_result,val_result),columns=['Train','Val'],index=['Loss','Acc'])
augmented_df
import matplotlib.pyplot as plt
import numpy as np
ypred_val = model_vgg19.predict(val1_ds[0][0])
ypred_val = np.array([1 if x > 0.5 else 0 for x in ypred_val])
y_val = val1_ds[0][-1]

print(confusion_matrix(y_val, ypred_val))
print('\n',classification_report(ypred_val,y_val))
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

ypred_val = model_vgg19.predict(val1_ds[0][0])
ypred_val = np.array([1 if x > 0.5 else 0 for x in ypred_val])
y_val = val1_ds[0][-1]

# Create a confusion matrix
cm = confusion_matrix(y_val, ypred_val)

# Define class labels for better visualization
class_labels = ['0', '1']

# Plot the confusion matrix
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_labels))
plt.xticks(tick_marks, class_labels, rotation=45)
plt.yticks(tick_marks, class_labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')

# Add values to the confusion matrix plot
for i in range(len(class_labels)):
    for j in range(len(class_labels)):
        plt.text(j, i, cm[i, j],
                 horizontalalignment='center',
                 color='white' if cm[i, j] > cm.max() / 2 else 'black')

plt.show()

# plot learning curve
def plot_learning_curve(history):
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.plot(epochs, acc, label='training acc')
    plt.plot(epochs, val_acc, label='validation acc')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy-%')
    plt.legend()
    plt.figure()

    plt.plot(epochs, loss, label='training loss')
    plt.plot(epochs, val_loss, label='validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

plot_learning_curve(history)
